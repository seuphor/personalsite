---
layout: blog
---

<div class="blog-body">
	<div style="background-image: url({{site.baseurl}}/img/general/profile_bg.png);" class="blog-cover">
		<div class="info-table">
			<div class="center">
				<img style="border-radius: 100%; border: 5px solid #f1f1f1; */" class="block-center" src="{{site.baseurl}}/img/general/profile_pic.png">
				<div class="block-center text-center">
					<h3 style="color: #f7ca9e;">Seuphor</h3>
					<p style="font-weight: bold; color: #e06c06;">Data & 3D Modeling</p>
					<p style="color: #f7ca9e;">A random person who loves designing awesome things. Having some experience of Python, C#, Unity, C4D, Photoshop, After Effect</p>
				</div>
				<div class="center">
					<ul class="blog-nav">
						<li>
							<a style="color: #f7ca9e;" href="https://github.com/seuphor">Github</a>
						</li>
						<li>
							<a style="color: #f7ca9e;" href="http://space.bilibili.com/348002?from=search&seid=1219523313562168988#!/">BiliBili</a>
						</li>
					</ul>
				</div>
			</div>
		</div>
	</div>

	<div class="blog-content container">
		<div class="blog-head text-center">
			<h2>Style Transfer with VGG</h2>
			<p>2017-05-25 @ 15:18:01</p>
		</div>
		<div class="blog-container">
			<div class="bigger-header">
				1. Initiatives & Brief Intro
			</div>

			<div class="text-body">
				&emsp; As we all know, there are a lot softwares for photo / video editting. However, mastering the concept of photo editting is very time-consuming and requires the decent knowledge of aesthetics. After learning the concept of Convolutional Neural Network, I am wondering if we can use convolutional neural net to automatically generate some images that is not ubiquitous aesthetically pleasing for people. The first idea that comes into my mind is doing style transfer for images (that is to transfer style from one specific image to another image). Since CNN is widely used for object detection and object classification, I think the same architecture can be used for image style transfer with appropriate changes in the pipeline.<br><br>

				&emsp; After spending some time, perusing the related research paper. I am able to implement deep learning style transfer algorithm in python. I will discuss more about implementation detail in the following section.
			</div>

			<div class="bigger-header">
				2. Tools
			</div>

			<div class="text-body">
				Language:<br>
					&emsp; Python<br><br>
				Package:<br>
					&emsp; Tensorflow - Building & Training CNNs<br>
					&emsp; OpenCV - Processing Image Input & Output<br>
					&emsp; Numpy - General Usage<br>
			</div>

			<div class="bigger-header">
				3. Prerequisite
			</div>

			<div class="text-body">
				&emsp; In order to understand the basic ideas and algorithms behind deep learning style transfer, you need to have basic understanding on linear algebra and calculus. If you are confused about different layers inside Convolutional Neural Network (such as convoltional layer, rectified layer, max-pooling layer, etc), I recommend you to use google search engine for detailed explaination.
			</div>

			<div class="bigger-header">
				4. CNN Architecture:
			</div>

			<div class="text-body">
				&emsp; The overall CNN architecture for style transfering I used in this implementation is the same as VGG-19, which consist of 5 pooling layers for down-sampling + several convoluational layers. The last feature extractor layer has 512 channels (512 dimensions of feature representation). The reason why we use VGG-19 architecture is that when convolutional neural networks are trained for object recognition, the neural network learns semantic representation of various object across the training samples. Later, these feature representation of objects can be used in style transfer task to define which pixels in the target image should be changed based on feature representation of style images and how should they change.<br><br>

				&emsp; Because training a convolutional neural net from scratch is very time-consuming and requires a lot training samples to fine-tune the parameters, I decide to use pre-trained Neural Net parameters for the sake of the time. Here I attach architectures from a reaserch paper called "Image Style Transfer Using Convolutional Neural Networks".
			</div>

			<div class="img-container">
				<img class="img-auto" src="{{site.baseurl}}/img/style-transfer/neural_style.png">
			</div>

			<div class="smaller-header">
				A. Parameters For Optimization:
			</div>

			<div class="text-body">
				&emsp; Instead of outputing class score for object classification, the main goal of our network is to produce a mixed-stylized image that is the same size of original image. Therefore, rather than optimizing weights and bias in each convoluational layers. We want to optimize pixel value in generated image to make it look similar to base image (using content loss) and the style image (using style loss)
			</div>

			<div class="smaller-header">
				B. Content Representation:
			</div>

			<div class="text-body">
				&emsp; In Convolutional Neural Network, each layer stores some information of original images. Therefore, we can use these feature representation that is generated by feeding raw image into CNN to evaluate content of the image (what specific object exist in the image). To visualize the difference of two images, one can inject both of the image into CNN and compare one image's output of the feature maps to those of another images. Follow this logic, we can define the loss between two images by measuring the euclidean distance of the values in feature maps. Using this loss function, we can update the pixel value for our generated image. In this case, we use feature representation of conv4_2 for content loss evaluation
			</div>

			<div class="img-container">
				<img class="img-auto-small" src="{{site.baseurl}}/img/cascade_cnn/calib_net.png">
			</div>

			<div class="smaller-header">
				C. Style Representation:
			</div>
			
			<div class="text-body">
				&emsp;  Different from content representation, which is the euclidean distance of values in feature maps between two images. The style representation of a image can be defined by using feature correlation matrix (by the transpose of feature map matrix multiply by feature map matrix itself). Then, style loss is defined by evaluatin the difference of feature correlation matrix between two images. We use this measurement because intuitively if two image is very similar in terms of the style, their feature correlation matrix should be very similar.
			</div>

			<div class="smaller-header">
				D. Image Denoise:
			</div>

			<div class="text-body">
				&emsp; To generate a pleasing picture using CNN, we need to make sure that the images is denoised to avoid random ugly pixels that is incompatible within the mood of the picture. Besides, loss function for content and style representation, we add one more loss function to evaluate the variation of the target pixel and its near-by pixel to reduce the noise of the image.
			</div>

			<div class="smaller-header">
				5. Optimization:
			</div>

			<div class="text-body">
				1. Loss Function:
					&emsp; The loss function of the overall architecture in this case will be: Total Loss = a * L(content) + b * L(style) + c * L(denoise). a, b, c are weighting factors for content, style, denoise loss. Using different weighting factors will result in different output pictures. I decide to use L-BFGS for optimization because this optimizer takes second-order derivatives into account when updating pixel values, which allows the network to come up with more refined images.
				2. Style vs. Content:
					&emsp; Choosing different values for a, b, c will produce different blended images. Normally, in this architecture, I recommend to use 5.0 for a, 1,000 for b, and .01 for c. Using lower b value for optimization process will result in a mixed picture that is very similar to the base image. However, using very high b value will produce a image that has very weird structures and the overall layout in base image cannot be found in the generated images.
			</div>

			<div class="smaller-header">
				7. Result Presentation:
			</div>

			<div class="text-body">
				&emsp; Here I provide some visual presentation about how the face recognition is done using self-built Cascade CNN. (Original_input -> After First Cascade CNN -> After Second Cascade CNN -> After Third Cascade CNN)
			</div>

			<div class="img-container">
				<img class="img-auto" src="{{site.baseurl}}/img/cascade_cnn/Complete_feed.jpg">
			</div>

			<div class="smaller-header">
				7. Acknowledge & Reference:
			</div>

			<div class="text-body">
				<a class="credit-source" href="http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/">(Faster) Non-Maximum Suppression in Python</a> BY by <b>Adrian Rosebrock</b><br><br>
				<a class="credit-source" href="http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/">A Convolutional Neural Network Cascade for Face Detection</a> BY <b>Li et al.</b>
			</div>

			<div class="smaller-header">
				8. Future Revision & Possibility:
			</div>

			<div class="text-body">
				&emsp; One of way to build a better model is to feed more training samples into CNNs. However, generating these training samples and training them will be very time consuming. For now, I have yet to labeled anime images for training. I hope there will be some in future.<br><br>

				&emsp; As for practical possibility, this network can definitely help anime website to distinguish between background images and images with faces. In addition, we can take a step further to use another CNNs to classify the facial expression of each faces which provides another filtering options for website users.
			</div>

			<div class="smaller-header">
				8. Next Up:
			</div>

			<div class="text-body">
				&emsp; I am thinking of using Bi-directional RNN with attention mechanism to build simple Q & A chatbot which is trained using Japanese anime scripts or Japanese movie scripts. However, finding training data might be a challenge. I will need to take some time to explore and see what I can find. Likewise, once I finalize the network, I will probably write another summary blog like this. Thanks for reading.
			</div>

			<div class="smaller-header">
				
			</div>
		</div>
	</div>
</div>

