---
layout: blog
---

<div class="blog-body">
	<div style="background-image: url({{site.baseurl}}/img/general/profile_bg.png);" class="blog-cover">
		<div class="info-table">
			<div class="center">
				<img style="border-radius: 100%; border: 5px solid #f1f1f1; */" class="block-center" src="{{site.baseurl}}/img/general/profile_pic.png">
				<div class="block-center text-center">
					<h3 style="color: #f7ca9e;">Seuphor</h3>
					<p style="font-weight: bold; color: #e06c06;">Data & 3D Modeling</p>
					<p style="color: #f7ca9e;">A random person who loves designing awesome things. Having some experience of Python, C#, Unity, C4D, Photoshop, After Effect</p>
				</div>
				<div class="center">
					<ul class="blog-nav">
						<li>
							<a style="color: #f7ca9e;" href="https://github.com/seuphor">Github</a>
						</li>
						<li>
							<a style="color: #f7ca9e;" href="http://space.bilibili.com/348002?from=search&seid=1219523313562168988#!/">BiliBili</a>
						</li>
					</ul>
				</div>
			</div>
		</div>
	</div>

	<div class="blog-content container">
		<div class="blog-head text-center">
			<h2>Generating Faces Using GANs</h2>
			<p>2017-08-08 @ 12:22:30</p>
		</div>
		<div class="blog-container">
			<div class="bigger-header">
				1. Initiatives & Brief Intro
			</div>

			<div class="text-body">
				&emsp; Even though deep learning architecture / algorithm can achieved very exciting result, these result can only be achieved when we have comparatively large and well-labeled dataset. When I try to implement some of deep learning algorithm for some anime-related tasks, I found out that it is very hard to find well-documented dataset and I am forced to collect and label all the training / validation samples by myself, which is very inefficient. As the time pass by, I start to wonder if there is some way for neural net to generate training samples by itself after seeing a subset of similar samples. <br><br>

				&emsp; Reading some of generative models in the field of deep learning, I noticed that Generative adversarial Neural Network can be used to generate imagained data based on the data it saw previously. Since I am very curious about how good this neural network can be, I use implemented an automatic face generation algorithm using GANs. <br><br>
			</div>

			<div class="bigger-header">
				2. Tools
			</div>

			<div class="text-body">
				Language:<br>
					&emsp; Python<br><br>
				Package:<br>
					&emsp; Tensorflow - Building & Training CNNs<br>
					&emsp; Numpy - General Usage<br>
			</div>

			<div class="bigger-header">
				3. Prerequisite
			</div>

			<div class="text-body">
				&emsp; In order to understand the basic ideas and algorithms behind deep learning style transfer, you need to have basic understanding on linear algebra and calculus. Feel free to "google" Generative Adversarial Neural Network for further detailed explanantion.
			</div>

			<div class="bigger-header">
				4. CNNs Architecture:
			</div>

			<div class="text-body">
				&emsp; The basic idea behind Generative Adversarial Neural Network is that instead of having a single Neural Network pipeline for doing classification, the overall architecture is consist of a discriminator network (a binary-classification network to identify whether the input image is real or fake) and a generator (a generative network that generate imaginary image based on white noise input). The logic can be briefly summarized as follow, even though the generator is very poor at generating imagined image at the beginning, after the training over time, discriminator become better at identifying the fake image from the real one and generator become better at generating real images in order to battle against the discriminator. At the end, the generator is preserved while the discriminator head is discarded for generating purpose.
			</div>

			<div class="img-container">
				<img class="img-auto" src="{{site.baseurl}}/img/gans/generative-adversarial-network.png">
			</div>

			<div class="smaller-header">
				A. Discriminator
			</div>

			<div class="text-body">
				&emsp; Since our training samples are pixel-based images, we will use convolutional layer and max-pooling layer for binary-classification. The input to discrinimator network will come from two different sources (28x28 human face image that is extracted from dataset / 28x28 imagined iamge that is generated from generator). The network parameter is optimized by setting all the images coming from dataset as positive exmaples and all the images generated from generator as negative examples. 
			</div>

			<div class="smaller-header">
				B. Generator:
			</div>

			<div class="text-body">
				&emsp; Similarily, we will use deconvolutional layer with batch normalization layer for generator head. The input to the generator head will be 100 dimension ranodmly generated value vector. The output of the network will be 28x28 pixel images. The parameter of generator is trained by feeding the generated images into discriminator network and evaluated the confidence score of being identified as positive samples. Based on this value loss, we will be able to back-prop into generator network and force the network to create better image which discriminator may have higher chance to identify it as a positive sample.
			</div>

			<div class="smaller-header">
				5. Result Presentation:
			</div>

			<div class="text-body">
				&emsp; Here is network generated faces over time. We can see that the generator network will be able to generate image that has decent characteristics of faces.
			</div>

			<div class="img-container">
				<div class="col-md-4">
					<p style="float: left;">123</p>
					<img class="img-auto" src="http://via.placeholder.com/650x450">
				</div>
				<div class="col-md-4">
					<p style="float: left;">123</p>
					<img class="img-auto" src="http://via.placeholder.com/650x450">
				</div>
				<div class="col-md-4">
					<p style="float: left;">123</p>
					<img class="img-auto" src="http://via.placeholder.com/650x450">
				</div>
			</div>

			<div class="smaller-header">
				6. Acknowledge & Reference:
			</div>

			<div class="text-body">
				<a class="credit-source" href="https://arxiv.org/pdf/1606.03498.pdf">Improved Techniques for Training GANs</a> BY <b>Tim et al.</b><br><br>
				<a class="credit-source" href="https://arxiv.org/pdf/1406.2661.pdf">Generative Adversarial Nets</a> BY <b>Ian et al.</b>
			</div>

			<div class="smaller-header">
				7. Future Application:
			</div>

			<div class="text-body">
				&emsp; Even though it is comparatively difficult to train GANs versus Basic CNN architecture due to complexity in the loss function, if implement appropriately, GANs may become a very useful toolkit in the future. For instance, we can use GANs to generate imagined training samples and use them for semi-supervised training process. Furthermore, we can utilize the generative aspects of GANs to enable neural network to come up with its own design. In this case, when designing new layout or characters, designer can use these imagined pictures as a reference for new ideas.
			</div>

		</div>
	</div>
</div>